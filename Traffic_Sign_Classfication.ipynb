{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da67836",
   "metadata": {},
   "source": [
    "# Traffic Sign Classification - LeNet Deep Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61973f7",
   "metadata": {},
   "source": [
    "### by ReDay Zarra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8c0d1",
   "metadata": {},
   "source": [
    "This project utilizes the LeNet deep network architecture to classify 42 different types of traffic signs. LeNet refers to a convolutional neural network that can be used for computer vision and classification models. This project showcases a step-by-step implementation of the model as well as in-depth notes to customize the model further for higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4e7e7",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "358d581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26ea14",
   "metadata": {},
   "source": [
    "> Classic libraries that will help us read and analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "191606ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76835ab1",
   "metadata": {},
   "source": [
    "> Libraries used for plotting and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "090f8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3217f",
   "metadata": {},
   "source": [
    "> Using pickle package to open our data, not much use after that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f29fe",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604cdb0",
   "metadata": {},
   "source": [
    "Importing the data into three different sections: training, validation, and\n",
    "testing. Training data is used to train the network, testing data is used to test\n",
    "the trained network with data that it has never seen to see how it would perform in\n",
    "the real world. The validation dataset ensures that we avoid overfitting by showing\n",
    "the network validation data every epoch (or run) in a process called \n",
    "cross-validation to ensure that the network is not focusing on the details of the\n",
    "training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dbf755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./traffic-signs-data/train.p\", mode = 'rb') as training_data:\n",
    "    train = pickle.load(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c14357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./traffic-signs-data/valid.p\", mode = 'rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "198fc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./traffic-signs-data/test.p\", mode = 'rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960590f",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee884025",
   "metadata": {},
   "source": [
    "Splitting the data into our individual training, validation, and testing set variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9f41d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], train['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1c816",
   "metadata": {},
   "source": [
    "> Assigning the features of the training set as X_train and the dependent variable (labels) as y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "364d7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation, y_validation = valid['features'], valid['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b086a",
   "metadata": {},
   "source": [
    "> Assigning the features of the validation set as X_validation and the dependent variable (labels) as y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41b0abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf34b81",
   "metadata": {},
   "source": [
    "> Assigning the features of the testing set as X_test and the dependent variable (labels) as y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737dacc",
   "metadata": {},
   "source": [
    "### Checking the dimensions of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ad1f342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f68b7",
   "metadata": {},
   "source": [
    "> Gives us an output of a four element tuple. The first number is the quantity of images, the second is the width of image in pixels, the third is the height of the image, and the last number the depth - in this case the 3 tells us that the images are colored since they are being multiplied for both Red, Green, and Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e51f0d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f2d73",
   "metadata": {},
   "source": [
    "> Gives us a tuple of one element, which is a label for each image in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc2d3935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4410, 32, 32, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f442f",
   "metadata": {},
   "source": [
    "> A smaller subset only containing 4410 pictures, which are 32 x 32, and have a depth of 3 meaning they are colored with RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3f884d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12630, 32, 32, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b98a1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12630,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
